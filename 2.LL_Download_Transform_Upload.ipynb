{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to download, process and upload json files from s3 bucket to Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Pre'></a>\n",
    "### Pre-requisites to run notebook   \n",
    "1. [s3 Credentials](#s3Credentials)\n",
    "\n",
    "2. [Enter the name of a new s3 bucket where the processed files would be stored temporarily before being copied to Redshift DB](#Ns3Creds)\n",
    "\n",
    "3. [Redshift Credentials](#RCredentials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps implemented in the notebook:\n",
    "\n",
    "1. [Downloads batches of 20 files from s3 bucket (batch size can be changed to optimize the process)](#P1)  \n",
    "2. [Processes the files:](#P1)   \n",
    "    a)Converts to dataframe    \n",
    "    b)Changes date format to a more readable format  \n",
    "    c)Drops repetitive columns  \n",
    "    d)Changes column names to ensure adherence to Redshift's column naming convention    \n",
    "3. [Uploads the dataframe to the new s3 bucket in csv format](#P3)  \n",
    "4. [Appends the processed s3 file to Redshift table](#P4)  \n",
    "5. [Deletes the processed file from s3 to free up storage space](#P5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import datetime\n",
    "import psycopg2\n",
    "import re\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Don't include this in t\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert unix time to readable date \n",
    "\n",
    "def date_clean(df):\n",
    "    \n",
    "    dates = [ 'EventCreatedOn','ImpressionCreatedOn','CreatedOn']\n",
    "    \n",
    "    for date in dates:\n",
    "        if date == 'CreatedOn':\n",
    "            df[date] = df[date].str.extract('(\\d+)')\n",
    "            df[date] = df[date].astype(int)\n",
    "        df[date] = df[date]/1000\n",
    "        df[date] = pd.to_datetime(df[date],unit='s')\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to change column names to ensure adherence to Redshift's column naming convention\n",
    "\n",
    "def column_renaming(df):\n",
    "    \n",
    "    column_list = df.columns.tolist()\n",
    "    \n",
    "    for col in column_list:\n",
    "        \n",
    "        col_old = copy.copy(col)\n",
    "        \n",
    "        # Replacing '.' and ':' with '_' as these characters are not allowed\n",
    "        col = (col.replace('.', '_'))\n",
    "        col = (col.replace(':', '_'))\n",
    "        \n",
    "        # As Redshift columns are case insensitive, column names with upper case letter to indicate start of a new word will not work\n",
    "        # Adding an '_' before upper case letters to aid comprehension after making the names lower case\n",
    "        col= '_'.join(re.sub( r\"([A-Z])\", r\" \\1\", col).split())\n",
    "        col = col.lower()\n",
    "        \n",
    "        # Replacing '__' with '_'\n",
    "        col = (col.replace('__', '_'))\n",
    "        \n",
    "        # Also checked for all column names being within the required length of 1 to 127 bytes\n",
    "        \n",
    "        # Rename column in the dataframe\n",
    "        df.rename(columns= {col_old:col}, inplace = True)\n",
    "    \n",
    "    \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract values from list columns as comma separated strings \n",
    "\n",
    "def extract_list(df,var1,var2):\n",
    "    \n",
    "    \n",
    "    df[var1] = [','.join(map(str, l)) for l in df[var1]]\n",
    "    df[var2] = [','.join(map(str, l)) for l in df[var2]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P3'></a>\n",
    "##### Uploads the dataframe to the new s3 bucket in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload file to S3\n",
    "\n",
    "def upload_file_S3(data_frame,tempfile_upload_bucket_name):\n",
    "    \n",
    "    print('Uploading single processed file:')\n",
    "    csv_buffer = StringIO()\n",
    "    data_frame.to_csv(csv_buffer, index=False)\n",
    "    s3 = boto3.resource('s3')\n",
    "    #Adding date and time to file name to identify the file\n",
    "    ts = datetime.datetime.now()\n",
    "    temp_file_name = 'temp_file'+str(ts)+'.csv'\n",
    "    s3.Object(tempfile_upload_bucket_name, temp_file_name).put(Body=csv_buffer.getvalue())\n",
    "    \n",
    "    return temp_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#Pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P4'></a>\n",
    "##### Appends the processed s3 file to Redshift table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload file from s3 to Redshift\n",
    "\n",
    "def upload_redshift(DBname,Port,User,Password,Host,aws_access_key_id,aws_secret_access_key,file_path,schema,table):\n",
    "\n",
    "    # Make conection to Redshift DB\n",
    "    try:\n",
    "        con = psycopg2.connect(\n",
    "                host='%s' % (Host),\n",
    "                user='%s' % (User),\n",
    "                port='%s' % (Port),\n",
    "                password='%s' % (Password),\n",
    "                dbname='%s' % (DBname)   )\n",
    "        print(\"Connection Successful!\")\n",
    "    except:\n",
    "        print(\"Unable to connect to Redshift\")\n",
    "        \n",
    "    cur = con.cursor()    \n",
    "     \n",
    "        \n",
    "    # query string to upload S3 file to table  \n",
    "      \n",
    "    sql='''COPY {schema}.{table}\n",
    "           FROM '{file_path}'\n",
    "           credentials 'aws_access_key_id={aws_access_key_id};aws_secret_access_key={aws_secret_access_key}'\n",
    "           IGNOREHEADER 1\n",
    "           DELIMITER ','\n",
    "           ACCEPTINVCHARS\n",
    "           EMPTYASNULL\n",
    "           MAXERROR 10 ;'''.format(schema=schema,\n",
    "                                   table=table, \n",
    "                                   file_path=file_path, \n",
    "                                   aws_access_key_id=aws_access_key_id,\n",
    "                                   aws_secret_access_key=aws_secret_access_key)\n",
    "    \n",
    "\n",
    "    #Execute the sql query \n",
    "    \n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "        con.commit()\n",
    "        print(\"Copy command executed successfully\")\n",
    "    except:\n",
    "        print(\"Failed to execute copy command\")\n",
    "    con.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#Pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P5'></a>\n",
    "###### Deletes the processed file from s3 to free up storage space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete temporary file from S3 (This is to ensure we are not taking up uncessary storage space)\n",
    "\n",
    "def delete_file(tempfile_upload_bucket_name,file_to_delete_name):\n",
    "    \n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    s3.Object(tempfile_upload_bucket_name, file_to_delete_name).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#Pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s3Credentials'></a>\n",
    "#### s3  Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 bucket details\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name ='leafliink-data-interview-exercise'\n",
    "my_bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "#Enter the aws credential here\n",
    "aws_access_key_id = 'Enter access key id'\n",
    "aws_secret_access_key = 'Enter secret accesskey'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#Pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='RCredentials'></a>\n",
    "#### Redshift redentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the Redshift DB credentials here\n",
    "DBname= 'Enter the dbname'\n",
    "Port= 'Enter port'\n",
    "User ='Enter user'\n",
    "Password ='Enter password'\n",
    "Host ='Enter host'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#Pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Ns3Creds'></a>\n",
    "\n",
    "\n",
    "#### New s3 Bucket for temporary storage of processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a s3 bucket to store temporary files for copying to Redshift table\n",
    "tempfile_upload_bucket_name ='Enter the s3 bucketname to store temporary processed files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#Pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P1'></a>\n",
    "### Batch processing and uploading files       \n",
    "Steps:    \n",
    "1. Download batches of 20 files from S3 bucket (batch size can be changed to optimize the process)\n",
    "2. Process the files (convert to dataframe, change date format, drop repetitive columns)\n",
    "3. Upload the dataframe to S3 bucket in csv format\n",
    "4. Append the processed S3 file to Redshift table\n",
    "5. Delete the processed file from S3 (save on storage space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Details:\n",
      " Start: 0 Upto: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghamitradutta/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Clicks: (20, 57) Imp: (0, 0) Count: 20\n",
      "Batch Details:\n",
      " Start: 20 Upto: 39\n",
      " Clicks: (20, 57) Imp: (0, 0) Count: 40\n",
      "Batch Details:\n",
      " Start: 40 Upto: 59\n",
      " Clicks: (20, 57) Imp: (0, 0) Count: 60\n",
      "Batch Details:\n",
      " Start: 60 Upto: 79\n",
      " Clicks: (9, 57) Imp: (19, 62) Count: 80\n"
     ]
    }
   ],
   "source": [
    "#Making a list of all keys in S3 bucket to aid in batch processing of files\n",
    "all_keys =[]\n",
    "for my_bucket_object in my_bucket.objects.all():\n",
    "    all_keys.append(my_bucket_object.key)\n",
    "\n",
    "batch = 20\n",
    "start = 0\n",
    "count = 0\n",
    "\n",
    "# Process s3 json files in batches of 20, i.e. download from s3, clean up and upload\n",
    "\n",
    "while start < len(all_keys):\n",
    "    \n",
    "    df_clicks = pd.DataFrame()\n",
    "    df_impressions = pd.DataFrame()\n",
    "    \n",
    "    print('Batch Details:\\n','Start:',start, 'Upto:', start+batch-1)\n",
    "    \n",
    " \n",
    "    for key in all_keys[start:start+batch]:\n",
    "        count+=1\n",
    "        if 'clicks' in key: \n",
    "            s3_object = s3.Object(bucket_name, key).get()['Body'].read().decode('utf-8')\n",
    "            for each_dict in s3_object.split('\\n')[:-1]:\n",
    "                each_dict = json.loads(each_dict)\n",
    "                \n",
    "                # Using json_normalize to convert keys in nested dictionaries to individual columns\n",
    "                df_new= pd.DataFrame( json_normalize(each_dict))\n",
    "                \n",
    "                # Change date format \n",
    "                df_new = date_clean(df_new)\n",
    "                \n",
    "                # Drop repetative columns with the same informations ('User.Key' and 'UserKey')\n",
    "                del df_new['User.Key']\n",
    "                \n",
    "                # Function to extract values from list columns as comma separated strings \n",
    "                df_new = extract_list(df_new,'MatchingKeywords','Categories')\n",
    "                \n",
    "                # Change column names in accordance to Redshift convention\n",
    "                df_new = column_renaming(df_new)\n",
    "                \n",
    "                # Append processed dataframe to main dataframe for batch batch upload later\n",
    "                df_clicks = df_clicks.append(df_new, ignore_index = True)\n",
    "                          \n",
    "                \n",
    "        else:\n",
    "            if 'impressions' in key: \n",
    "                s3_object = s3.Object(bucket_name, key).get()['Body'].read().decode('utf-8')\n",
    "                for each_dict in s3_object.split('\\n')[:-1]:\n",
    "                    each_dict = json.loads(each_dict)\n",
    "                    \n",
    "                    # Using json_normalize to convert keys in nested dictionaries like User to individual columns User.Key and User.IsNew\n",
    "                    df_new= pd.DataFrame( json_normalize(each_dict))\n",
    "\n",
    "                    # Change date format\n",
    "                    df_new = date_clean(df_new)\n",
    "                    \n",
    "                    # Drop repetitive columns with the same informations ('User.Key' and 'UserKey')\n",
    "                    del df_new['User.Key']\n",
    "                    \n",
    "                    # Function to extract values from list columns as comma separated strings \n",
    "                    df_new = extract_list(df_new,'MatchingKeywords','Categories')\n",
    "                    \n",
    "                    # Change column names in accordance to Redshift convention\n",
    "                    df_new = column_renaming(df_new)\n",
    "\n",
    "                    # Append processed dataframe to main dataframe for batch batch upload later\n",
    "                    df_impressions = df_impressions.append(df_new, ignore_index = True)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    \n",
    "    print(' Clicks:', df_clicks.shape, 'Imp:',df_impressions.shape,'Count:',count)\n",
    "    \n",
    "    \n",
    "    # Upload to processed batch of 20 json files to redshift database table\n",
    "    \n",
    "    # upload files to S3\n",
    "    filename_clicks = upload_files_S3(df_clicks,tempfile_upload_bucket_name) \n",
    "    filename_imp = upload_files_S3(df_impressions,tempfile_upload_bucket_name) \n",
    "     \n",
    "    # upload files from S3 to Redshift table\n",
    "    file_path_clicks = 's3://'+tempfile_upload_bucket_name+'/'+filename_clicks\n",
    "    file_path_imp = 's3://'+tempfile_upload_bucket_name+'/'+filename_imp\n",
    "    upload_redshift(DBname,Port,User,Password,Host,aws_access_key_id,aws_secret_access_key,\\\n",
    "                    file_path_clicks ,'ll_schema','clicks') \n",
    "    upload_redshift(DBname,Port,User,Password,Host,aws_access_key_id,aws_secret_access_key,\\\n",
    "                    file_path_imp ,'ll_schema','impressions')\n",
    "    \n",
    "    # Delete temporary files from S3 \n",
    "    delete_file(tempfile_upload_bucket_name,file_to_delete_name) \n",
    "    delete_file(tempfile_upload_bucket_name,file_to_delete_name) \n",
    "    \n",
    "    \n",
    "    #Changing start value for processing the next batch of 20 json files\n",
    "    start = start + batch\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#Pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_schema</th>\n",
       "      <th>meta_version</th>\n",
       "      <th>gdpr_computed</th>\n",
       "      <th>gdpr_source</th>\n",
       "      <th>remote_i_p</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>ecpm</th>\n",
       "      <th>datacenter</th>\n",
       "      <th>burn_in</th>\n",
       "      <th>is_valid_u_a</th>\n",
       "      <th>...</th>\n",
       "      <th>device_brand_name</th>\n",
       "      <th>device_model_name</th>\n",
       "      <th>device_os_raw_version</th>\n",
       "      <th>device_os_major_version</th>\n",
       "      <th>device_os_minor_version</th>\n",
       "      <th>device_browser</th>\n",
       "      <th>device_browser_raw_version</th>\n",
       "      <th>device_browser_major_version</th>\n",
       "      <th>device_browser_minor_version</th>\n",
       "      <th>device_form_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chrome Desktop</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chrome Desktop</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chrome Desktop</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chrome Desktop</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chrome Desktop</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  meta_schema meta_version  gdpr_computed gdpr_source remote_i_p user_agent  \\\n",
       "0       event          1.3           True        none    0.0.0.0              \n",
       "1       event          1.3           True        none    0.0.0.0              \n",
       "2       event          1.3           True        none    0.0.0.0              \n",
       "3       event          1.3           True        none    0.0.0.0              \n",
       "4       event          1.3           True        none    0.0.0.0              \n",
       "\n",
       "   ecpm  datacenter  burn_in  is_valid_u_a  ... device_brand_name  \\\n",
       "0     0       False    False          True  ...            Google   \n",
       "1     0       False    False          True  ...            Google   \n",
       "2     0       False    False          True  ...            Google   \n",
       "3     0       False    False          True  ...            Google   \n",
       "4     0       False    False          True  ...            Google   \n",
       "\n",
       "   device_model_name device_os_raw_version device_os_major_version  \\\n",
       "0             Chrome                     0                       0   \n",
       "1             Chrome                     0                       0   \n",
       "2             Chrome                     0                       0   \n",
       "3             Chrome                     0                       0   \n",
       "4             Chrome                     0                       0   \n",
       "\n",
       "  device_os_minor_version  device_browser  device_browser_raw_version  \\\n",
       "0                       0  Chrome Desktop                        79.0   \n",
       "1                       0  Chrome Desktop                        79.0   \n",
       "2                       0  Chrome Desktop                        79.0   \n",
       "3                       0  Chrome Desktop                        79.0   \n",
       "4                       0  Chrome Desktop                        79.0   \n",
       "\n",
       "   device_browser_major_version  device_browser_minor_version  \\\n",
       "0                            79                             0   \n",
       "1                            79                             0   \n",
       "2                            79                             0   \n",
       "3                            79                             0   \n",
       "4                            79                             0   \n",
       "\n",
       "  device_form_factor  \n",
       "0            desktop  \n",
       "1            desktop  \n",
       "2            desktop  \n",
       "3            desktop  \n",
       "4            desktop  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clicks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_schema</th>\n",
       "      <th>meta_version</th>\n",
       "      <th>gdpr_computed</th>\n",
       "      <th>gdpr_source</th>\n",
       "      <th>remote_i_p</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>ecpm</th>\n",
       "      <th>datacenter</th>\n",
       "      <th>burn_in</th>\n",
       "      <th>is_valid_u_a</th>\n",
       "      <th>...</th>\n",
       "      <th>device_brand_name</th>\n",
       "      <th>device_model_name</th>\n",
       "      <th>device_os_raw_version</th>\n",
       "      <th>device_os_major_version</th>\n",
       "      <th>device_os_minor_version</th>\n",
       "      <th>device_browser</th>\n",
       "      <th>device_browser_raw_version</th>\n",
       "      <th>device_browser_major_version</th>\n",
       "      <th>device_browser_minor_version</th>\n",
       "      <th>device_form_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chrome Desktop</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chrome Desktop</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Firefox</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Firefox Desktop</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chrome Desktop</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>event</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Firefox</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Firefox Desktop</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  meta_schema meta_version  gdpr_computed gdpr_source remote_i_p user_agent  \\\n",
       "0       event          1.3           True        none    0.0.0.0              \n",
       "1       event          1.3           True        none    0.0.0.0              \n",
       "2       event          1.3           True        none    0.0.0.0              \n",
       "3       event          1.3           True        none    0.0.0.0              \n",
       "4       event          1.3           True        none    0.0.0.0              \n",
       "\n",
       "   ecpm  datacenter  burn_in  is_valid_u_a  ... device_brand_name  \\\n",
       "0     0       False    False          True  ...            Google   \n",
       "1     0       False    False          True  ...            Google   \n",
       "2     0       False    False          True  ...           Mozilla   \n",
       "3     0       False    False          True  ...            Google   \n",
       "4     0       False    False          True  ...           Mozilla   \n",
       "\n",
       "   device_model_name device_os_raw_version device_os_major_version  \\\n",
       "0             Chrome                     0                       0   \n",
       "1             Chrome                     0                       0   \n",
       "2            Firefox                                             0   \n",
       "3             Chrome                     0                       0   \n",
       "4            Firefox                                             0   \n",
       "\n",
       "   device_os_minor_version   device_browser device_browser_raw_version  \\\n",
       "0                        0   Chrome Desktop                       79.0   \n",
       "1                        0   Chrome Desktop                       79.0   \n",
       "2                        0  Firefox Desktop                       72.0   \n",
       "3                        0   Chrome Desktop                       79.0   \n",
       "4                        0  Firefox Desktop                       72.0   \n",
       "\n",
       "  device_browser_major_version  device_browser_minor_version  \\\n",
       "0                           79                             0   \n",
       "1                           79                             0   \n",
       "2                           72                             0   \n",
       "3                           79                             0   \n",
       "4                           72                             0   \n",
       "\n",
       "   device_form_factor  \n",
       "0             desktop  \n",
       "1             desktop  \n",
       "2             desktop  \n",
       "3             desktop  \n",
       "4             desktop  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_impressions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back](#Pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
